# üöÄ TECHNISCHE OPTIMIERUNGEN V18.3

**Vorschl√§ge f√ºr MyDispatch - Systematische Weiterentwicklung**

---

## üéØ Executive Summary

Diese Dokumentation listet **ALLE identifizierten technischen Optimierungen** f√ºr MyDispatch auf, geordnet nach:

1. **Priorit√§t** (üî¥ KRITISCH ‚Üí üü¢ ENHANCEMENT)
2. **Kategorien** (Backend, Frontend, DevOps, Security, UX)
3. **Aufwand** (Stunden)
4. **Business-Impact** (Geld, Zeit, Rechtssicherheit)

**Aktuelle Metriken:**

- ‚úÖ 75% Code-Zentralisierung
- ‚úÖ 0 TypeScript-Errors
- üîÑ 127 Anti-Patterns identifiziert (Sprint 47)
- üîÑ 40% Code-Duplikation (wird reduziert Sprint 49-55)

---

## üìä TEIL 1: BACKEND-OPTIMIERUNGEN

### üî¥ KRITISCH (Sprint 49-50)

#### 1.1 Materialized View Refresh-Automation

**Problem:** `mv_document_expiry_dashboard` wird nicht automatisch aktualisiert
**Impact:** Veraltete Compliance-Daten im Dashboard

**L√∂sung:**

```sql
-- Supabase Cron-Extension verwenden
CREATE EXTENSION IF NOT EXISTS pg_cron;

-- T√§gliches Refresh um 02:00 Uhr
SELECT cron.schedule(
  'refresh-document-dashboard',
  '0 2 * * *',  -- Jeden Tag um 02:00
  'REFRESH MATERIALIZED VIEW CONCURRENTLY mv_document_expiry_dashboard;'
);
```

**Aufwand:** 1 Stunde
**Impact:** Compliance-Daten immer aktuell (rechtliche Sicherheit)

---

#### 1.2 Database Partitioning (Bookings-Tabelle)

**Problem:** `bookings`-Tabelle w√§chst unbegrenzt ‚Üí Performance-Probleme bei >50.000 Eintr√§gen
**Impact:** Langsame Abfragen, hohe Ladezeiten

**L√∂sung:** Range-Partitioning nach `pickup_time` (monatlich)

```sql
-- Partitioning nach Monat
CREATE TABLE bookings_2025_01 PARTITION OF bookings
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE bookings_2025_02 PARTITION OF bookings
  FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- Automatisches Erstellen neuer Partitionen (Funktion)
CREATE OR REPLACE FUNCTION create_monthly_booking_partition()
RETURNS void AS $$
DECLARE
  partition_name TEXT;
  start_date DATE;
  end_date DATE;
BEGIN
  start_date := DATE_TRUNC('month', NOW() + INTERVAL '1 month');
  end_date := start_date + INTERVAL '1 month';
  partition_name := 'bookings_' || TO_CHAR(start_date, 'YYYY_MM');

  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %I PARTITION OF bookings FOR VALUES FROM (%L) TO (%L)',
    partition_name, start_date, end_date
  );
END;
$$ LANGUAGE plpgsql;

-- Monatlicher Cron-Job
SELECT cron.schedule(
  'create-booking-partition',
  '0 0 1 * *',  -- Am 1. jeden Monats
  'SELECT create_monthly_booking_partition();'
);
```

**Aufwand:** 4 Stunden
**Impact:**

- Query-Performance +60%
- Skalierbar bis 1 Mio+ Eintr√§ge

---

#### 1.3 Database Indexes Optimierung

**Problem:** Fehlende Composite-Indexes f√ºr h√§ufige Queries
**Impact:** Langsame Filter-Abfragen

**L√∂sung:**

```sql
-- Bookings: H√§ufigste Filter
CREATE INDEX CONCURRENTLY idx_bookings_company_status_date
  ON bookings (company_id, status, pickup_time DESC)
  WHERE archived = false;

-- Drivers: Suche + Verf√ºgbarkeit
CREATE INDEX CONCURRENTLY idx_drivers_company_shift_name
  ON drivers (company_id, shift_status, first_name, last_name)
  WHERE archived = false;

-- Vehicles: Status + Klasse
CREATE INDEX CONCURRENTLY idx_vehicles_company_status_class
  ON vehicles (company_id, status, vehicle_class)
  WHERE archived = false;

-- Documents: Expiry-Tracking
CREATE INDEX CONCURRENTLY idx_documents_entity_expiry
  ON documents (company_id, entity_type, entity_id, expiry_date)
  WHERE archived = false AND expiry_date > CURRENT_DATE - INTERVAL '90 days';
```

**Aufwand:** 2 Stunden
**Impact:**

- Query-Performance +40%
- Reduzierte DB-Load

---

### üü° WICHTIG (Sprint 51-52)

#### 1.4 Connection Pooling (Supabase Pooler)

**Problem:** Viele Frontend-Clients ‚Üí viele DB-Connections
**Impact:** Connection-Limit erreicht, Errors

**L√∂sung:** Supabase Pooler aktivieren (Transaction-Mode)

```typescript
// Frontend: Pooler-URL verwenden
const supabaseUrl = import.meta.env.VITE_SUPABASE_POOLER_URL || import.meta.env.VITE_SUPABASE_URL;

const supabase = createClient(supabaseUrl, anonKey, {
  db: {
    schema: "public",
  },
  global: {
    headers: {
      "x-connection-type": "pooler",
    },
  },
});
```

**Aufwand:** 1 Stunde
**Impact:**

- Max. Connections: 15 ‚Üí 1.000+
- Stabilit√§t +90%

---

#### 1.5 Full-Text-Search (PostgreSQL)

**Problem:** Suche in Kunden/Fahrern langsam (LIKE-Queries)
**Impact:** Schlechte UX bei gro√üen Datenmengen

**L√∂sung:** Full-Text-Search mit GIN-Indexes

```sql
-- Customers: Kombinierter Search-Vector
ALTER TABLE customers
  ADD COLUMN search_vector tsvector
  GENERATED ALWAYS AS (
    setweight(to_tsvector('german', COALESCE(first_name, '')), 'A') ||
    setweight(to_tsvector('german', COALESCE(last_name, '')), 'A') ||
    setweight(to_tsvector('german', COALESCE(email, '')), 'B') ||
    setweight(to_tsvector('german', COALESCE(phone, '')), 'B') ||
    setweight(to_tsvector('german', COALESCE(company_name, '')), 'C')
  ) STORED;

CREATE INDEX idx_customers_search ON customers USING GIN(search_vector);

-- Query
SELECT * FROM customers
WHERE search_vector @@ to_tsquery('german', 'max:* & mustermann:*')
  AND company_id = 'xxx'
ORDER BY ts_rank(search_vector, to_tsquery('german', 'max:* & mustermann:*')) DESC;
```

**Aufwand:** 3 Stunden
**Impact:**

- Search-Performance +800%
- Fuzzy-Matching unterst√ºtzt

---

#### 1.6 Database Backup & Point-in-Time-Recovery

**Problem:** Keine regelm√§√üigen Backups au√üerhalb Supabase
**Impact:** Datenverlust-Risiko bei Supabase-Ausfall

**L√∂sung:** pg_dump Cron + S3-Upload

```bash
#!/bin/bash
# backup-db.sh (Edge Function via Cron)

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="mydispatch_backup_${TIMESTAMP}.sql.gz"

# Dump
pg_dump $SUPABASE_DB_URL | gzip > /tmp/$BACKUP_FILE

# Upload to S3 (AWS, Backblaze, etc.)
aws s3 cp /tmp/$BACKUP_FILE s3://mydispatch-backups/$BACKUP_FILE

# Cleanup (behalte nur 30 Tage)
find /tmp -name "mydispatch_backup_*.sql.gz" -mtime +30 -delete
```

**Cron:** T√§glich 03:00 Uhr

**Aufwand:** 4 Stunden
**Impact:**

- Disaster-Recovery innerhalb 1 Stunde
- DSGVO-Konformit√§t (Datensicherheit)

---

### üü¢ ENHANCEMENT (Sprint 53+)

#### 1.7 Read Replicas (f√ºr Reports)

**Problem:** Heavy Reports blockieren Prod-DB
**Impact:** Langsame Writes w√§hrend Report-Generierung

**L√∂sung:** Supabase Read Replicas

```typescript
// Heavy Read-Only Queries an Replica
const replicaClient = createClient(process.env.SUPABASE_REPLICA_URL, process.env.SUPABASE_ANON_KEY);

// Statistiken-Reports
const stats = await replicaClient
  .from("bookings")
  .select("*")
  .gte("pickup_time", startDate)
  .lte("pickup_time", endDate);
```

**Kosten:** ~30‚Ç¨/Monat (Replica)

**Aufwand:** 2 Stunden
**Impact:**

- Main-DB entlastet
- Report-Performance +50%

---

## üé® TEIL 2: FRONTEND-OPTIMIERUNGEN

### üî¥ KRITISCH (Sprint 49-50)

#### 2.1 React Query Optimistic Updates

**Problem:** UI wartet auf API-Response ‚Üí Verz√∂gerung
**Impact:** Schlechte UX (langsam wirkend)

**L√∂sung:**

```typescript
// Optimistic Update Pattern
const updateBookingMutation = useMutation({
  mutationFn: async (data) => {
    const { error } = await supabase.from("bookings").update(data).eq("id", bookingId);
    if (error) throw error;
  },
  onMutate: async (newData) => {
    // Cancel outgoing queries
    await queryClient.cancelQueries({ queryKey: ["bookings"] });

    // Snapshot previous value
    const previousBookings = queryClient.getQueryData(["bookings"]);

    // Optimistically update cache
    queryClient.setQueryData(["bookings"], (old) =>
      old.map((b) => (b.id === bookingId ? { ...b, ...newData } : b))
    );

    return { previousBookings };
  },
  onError: (err, newData, context) => {
    // Rollback on error
    queryClient.setQueryData(["bookings"], context.previousBookings);
    toast.error("Fehler beim Speichern");
  },
  onSettled: () => {
    queryClient.invalidateQueries({ queryKey: ["bookings"] });
  },
});
```

**Aufwand:** 6 Stunden (alle Mutations)
**Impact:**

- Gef√ºhlte Performance +200%
- Bessere UX

---

#### 2.2 Virtual Scrolling (Lange Listen)

**Problem:** Tabellen mit >500 Eintr√§gen langsam
**Impact:** Scrolling ruckelt, hoher RAM-Verbrauch

**L√∂sung:** @tanstack/react-virtual

```typescript
// VirtualizedTable.tsx
import { useVirtualizer } from '@tanstack/react-virtual';

function VirtualizedTable({ data }: { data: Booking[] }) {
  const parentRef = useRef<HTMLDivElement>(null);

  const virtualizer = useVirtualizer({
    count: data.length,
    getScrollElement: () => parentRef.current,
    estimateSize: () => 60, // Row-Height
    overscan: 10,
  });

  return (
    <div ref={parentRef} style={{ height: '600px', overflow: 'auto' }}>
      <div style={{ height: `${virtualizer.getTotalSize()}px`, position: 'relative' }}>
        {virtualizer.getVirtualItems().map((virtualRow) => {
          const booking = data[virtualRow.index];

          return (
            <div
              key={virtualRow.key}
              style={{
                position: 'absolute',
                top: 0,
                left: 0,
                width: '100%',
                height: `${virtualRow.size}px`,
                transform: `translateY(${virtualRow.start}px)`,
              }}
            >
              <BookingRow booking={booking} />
            </div>
          );
        })}
      </div>
    </div>
  );
}
```

**Aufwand:** 4 Stunden
**Impact:**

- Rendering-Performance +500%
- Scrolling 60fps

---

#### 2.3 Code-Splitting (Lazy Loading)

**Problem:** Gro√ües Initial-Bundle (2MB+)
**Impact:** Langsame Ladezeit

**L√∂sung:**

```typescript
// Route-Based Code-Splitting
const Dashboard = lazy(() => import('@/pages/Dashboard'));
const Auftraege = lazy(() => import('@/pages/Auftraege'));
const Kunden = lazy(() => import('@/pages/Kunden'));

// Component-Based Code-Splitting
const HeavyChart = lazy(() => import('@/components/charts/RevenueChart'));

<Suspense fallback={<LoadingSpinner />}>
  <HeavyChart data={data} />
</Suspense>
```

**Aufwand:** 2 Stunden
**Impact:**

- Initial-Bundle: 2MB ‚Üí 400KB (-80%)
- Time-to-Interactive: -3s

---

### üü° WICHTIG (Sprint 51-52)

#### 2.4 Service Worker (PWA Offline-Funktionalit√§t)

**Problem:** App offline nicht nutzbar
**Impact:** Schlechte UX bei schwacher Verbindung

**L√∂sung:** Workbox mit Cache-First-Strategie

```typescript
// vite-plugin-pwa config
PWA({
  strategies: "injectManifest",
  srcDir: "src",
  filename: "sw.ts",
  manifest: {
    name: "MyDispatch",
    short_name: "MyDispatch",
    theme_color: "#EADEBD",
    icons: [
      { src: "/icon-192.png", sizes: "192x192", type: "image/png" },
      { src: "/icon-512.png", sizes: "512x512", type: "image/png" },
    ],
  },
  workbox: {
    runtimeCaching: [
      {
        urlPattern: /^https:\/\/.*\.supabase\.co\/.*$/,
        handler: "NetworkFirst",
        options: {
          cacheName: "supabase-api",
          expiration: {
            maxEntries: 100,
            maxAgeSeconds: 60 * 60 * 24, // 24h
          },
        },
      },
      {
        urlPattern: /\.(js|css|png|jpg|jpeg|svg|woff2)$/,
        handler: "CacheFirst",
        options: {
          cacheName: "static-resources",
          expiration: {
            maxEntries: 200,
            maxAgeSeconds: 60 * 60 * 24 * 30, // 30 Tage
          },
        },
      },
    ],
  },
});
```

**Aufwand:** 8 Stunden
**Impact:**

- Offline-Nutzung (Read-Only)
- PWA-Install m√∂glich

---

#### 2.5 Prefetching & Preloading

**Problem:** Langsame Navigation zwischen Seiten
**Impact:** Gef√ºhlte Verz√∂gerung

**L√∂sung:**

```typescript
// React Query Prefetch bei Hover
const queryClient = useQueryClient();

<Link
  to="/auftraege"
  onMouseEnter={() => {
    queryClient.prefetchQuery({
      queryKey: ['bookings'],
      queryFn: fetchBookings,
    });
  }}
>
  Auftr√§ge
</Link>

// Preload Next Page
import { preloadRouteComponent } from 'react-router-dom';

useEffect(() => {
  if (currentPage === 'dashboard') {
    preloadRouteComponent('/auftraege');
  }
}, [currentPage]);
```

**Aufwand:** 3 Stunden
**Impact:**

- Navigation gef√ºhlt instant
- Bessere UX

---

### üü¢ ENHANCEMENT (Sprint 53+)

#### 2.6 Web Workers (Heavy Computations)

**Problem:** Sortierung/Filterung gro√üer Listen blockiert UI
**Impact:** UI friert ein

**L√∂sung:**

```typescript
// workers/sort-bookings.worker.ts
self.addEventListener("message", (e: MessageEvent) => {
  const { data, sortKey, sortOrder } = e.data;

  const sorted = data.sort((a, b) => {
    if (sortOrder === "asc") {
      return a[sortKey] > b[sortKey] ? 1 : -1;
    }
    return a[sortKey] < b[sortKey] ? 1 : -1;
  });

  self.postMessage(sorted);
});

// Usage
const sortWorker = new Worker(new URL("./workers/sort-bookings.worker.ts", import.meta.url), {
  type: "module",
});

sortWorker.postMessage({ data, sortKey, sortOrder });
sortWorker.addEventListener("message", (e) => {
  setSortedData(e.data);
});
```

**Aufwand:** 4 Stunden
**Impact:**

- UI bleibt responsive
- Sortierung +300% schneller

---

## üîí TEIL 3: SECURITY-OPTIMIERUNGEN

### üî¥ KRITISCH (Sprint 49)

#### 3.1 Rate Limiting (Edge Functions)

**Problem:** Keine Rate-Limits ‚Üí DDoS-Anf√§llig
**Impact:** Serverkosten explodieren

**L√∂sung:** Upstash Redis Rate-Limiting

```typescript
// Edge Function mit Rate-Limit
import { Ratelimit } from "@upstash/ratelimit";
import { Redis } from "@upstash/redis";

const redis = new Redis({
  url: Deno.env.get("UPSTASH_REDIS_URL")!,
  token: Deno.env.get("UPSTASH_REDIS_TOKEN")!,
});

const ratelimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(10, "10 s"), // 10 Requests / 10 Sekunden
});

Deno.serve(async (req) => {
  const ip = req.headers.get("x-forwarded-for") || "unknown";
  const { success } = await ratelimit.limit(ip);

  if (!success) {
    return new Response("Rate limit exceeded", { status: 429 });
  }

  // Normal processing
});
```

**Kosten:** Upstash Free Tier (10.000 Requests/Monat)

**Aufwand:** 2 Stunden
**Impact:**

- Schutz vor DDoS
- Kostenersparnis

---

#### 3.2 Input-Validation (Zod auf Backend)

**Problem:** Nur Frontend-Validation ‚Üí Umgehbar
**Impact:** Datenbank-Corruption m√∂glich

**L√∂sung:** Zod-Schemas auch in Edge Functions

```typescript
// Zentrales Validation-Schema
// src/lib/validation/schemas.ts (Frontend)
export const bookingSchema = z.object({
  pickup_address: z.string().min(5),
  dropoff_address: z.string().min(5),
  pickup_time: z.string().datetime(),
  price: z.number().positive(),
});

// Edge Function: Gleiche Schemas verwenden
import { bookingSchema } from "../shared/validation.ts";

Deno.serve(async (req) => {
  const body = await req.json();

  // Validation
  const result = bookingSchema.safeParse(body);
  if (!result.success) {
    return new Response(JSON.stringify({ error: result.error }), { status: 400 });
  }

  // Proceed
});
```

**Aufwand:** 4 Stunden
**Impact:**

- 100% sichere Inputs
- Keine Datenbank-Corruption

---

#### 3.3 SQL-Injection-Schutz (Prepared Statements)

**Problem:** Einige dynamische Queries unsicher
**Impact:** SQL-Injection m√∂glich

**L√∂sung:**

```typescript
// ‚ùå FALSCH (String-Concatenation)
const { data } = await supabase.rpc("search_customers", { query: `name LIKE '%${searchTerm}%'` });

// ‚úÖ RICHTIG (Parameterized Query)
const { data } = await supabase
  .from("customers")
  .select("*")
  .ilike("first_name", `%${searchTerm}%`)
  .eq("company_id", companyId);
```

**Aufwand:** 2 Stunden (Code-Review)
**Impact:**

- SQL-Injection unm√∂glich
- Security-Audit bestanden

---

### üü° WICHTIG (Sprint 51)

#### 3.4 CSRF-Protection (Edge Functions)

**Problem:** Edge Functions haben kein CSRF-Token
**Impact:** Cross-Site-Anfragen m√∂glich

**L√∂sung:**

```typescript
// CSRF-Token im Cookie
const csrfToken = crypto.randomUUID();

// Response mit CSRF-Cookie
return new Response(JSON.stringify({ success: true }), {
  headers: {
    "Set-Cookie": `csrf_token=${csrfToken}; SameSite=Strict; Secure; HttpOnly`,
  },
});

// Validation in nachfolgenden Requests
const cookieToken = req.headers.get("cookie")?.match(/csrf_token=([^;]+)/)?.[1];
const headerToken = req.headers.get("x-csrf-token");

if (cookieToken !== headerToken) {
  return new Response("CSRF validation failed", { status: 403 });
}
```

**Aufwand:** 3 Stunden
**Impact:**

- CSRF-Angriffe verhindert
- OWASP-konform

---

## üõ†Ô∏è TEIL 4: DEVOPS-OPTIMIERUNGEN

### üü° WICHTIG (Sprint 51-52)

#### 4.1 Monitoring & Alerting (Sentry + BetterStack)

**Problem:** Keine Echtzeit-√úberwachung von Errors
**Impact:** Bugs werden sp√§t entdeckt

**L√∂sung:**

```typescript
// Sentry-Integration (bereits vorhanden, erweitern)
import * as Sentry from '@sentry/react';

Sentry.init({
  dsn: import.meta.env.VITE_SENTRY_DSN,
  environment: import.meta.env.MODE,
  tracesSampleRate: 1.0,

  // Performance-Monitoring
  integrations: [
    new Sentry.BrowserTracing({
      routingInstrumentation: Sentry.reactRouterV6Instrumentation(
        useEffect,
        useLocation,
        useNavigationType,
        createRoutesFromChildren,
        matchRoutes
      ),
    }),
    new Sentry.Replay({
      maskAllText: false,
      blockAllMedia: false,
    }),
  ],

  // Session Replay f√ºr Fehler-Analyse
  replaysSessionSampleRate: 0.1,
  replaysOnErrorSampleRate: 1.0,
});

// Custom Error-Boundaries mit Context
<Sentry.ErrorBoundary
  fallback={<ErrorFallback />}
  beforeCapture={(scope) => {
    scope.setContext('user', {
      id: user.id,
      company: user.company_id,
      email: user.email,
    });
  }}
>
  <App />
</Sentry.ErrorBoundary>
```

**BetterStack Uptime-Monitoring:**

- API-Endpoints (alle 60s)
- Edge Functions
- Supabase DB

**Kosten:**

- Sentry: 26‚Ç¨/Monat (10K Events)
- BetterStack: Free Tier (50 Checks)

**Aufwand:** 4 Stunden
**Impact:**

- MTTR (Mean Time To Recovery): -75%
- Proaktive Error-Behebung

---

#### 4.2 Automated Testing (Playwright E2E)

**Problem:** Keine End-to-End-Tests
**Impact:** Regressions werden nicht erkannt

**L√∂sung:**

```typescript
// tests/e2e/booking-flow.spec.ts
import { test, expect } from '@playwright/test';

test.describe('Booking Flow', () => {
  test.beforeEach(async ({ page }) => {
    await page.goto('/login');
    await page.fill('[name="email"]', 'test@example.com');
    await page.fill('[name="password"]', 'password123');
    await page.click('[type="submit"]');
    await expect(page).toHaveURL('/dashboard');
  });

  test('Create new booking', async ({ page }) => {
    await page.goto('/auftraege');
    await page.click('button:has-text("Neuer Auftrag")');

    await page.fill('[name="pickup_address"]', 'M√ºnchen Hauptbahnhof');
    await page.fill('[name="dropoff_address"]', 'M√ºnchen Flughafen');
    await page.fill('[name="pickup_time"]', '2025-02-01T10:00');

    await page.click('button:has-text("Speichern")');

    await expect(page.locator('text=Auftrag erfolgreich erstellt')).toBeVisible();
  });

  test('Filter bookings by status', async ({ page }) => {
    await page.goto('/auftraege');
    await page.selectOption('[name="status"]', 'pending');

    const rows = page.locator('[data-status="pending"]');
    await expect(rows).toHaveCount(await rows.count());
  });
});

// CI/CD Integration (GitHub Actions)
// .github/workflows/e2e-tests.yml
name: E2E Tests
on: [pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm ci
      - run: npx playwright install
      - run: npm run test:e2e
```

**Aufwand:** 20 Stunden (Initial-Setup + Tests)
**Impact:**

- Bug-Detection +90%
- Regressions verhindert

---

#### 4.3 Performance-Budgets (Lighthouse CI)

**Problem:** Performance-Regression unbemerkt
**Impact:** Langsame App

**L√∂sung:**

```yaml
# lighthouserc.yml
ci:
  collect:
    url:
      - http://localhost:5173/
      - http://localhost:5173/dashboard
      - http://localhost:5173/auftraege
    numberOfRuns: 3
  assert:
    preset: lighthouse:recommended
    assertions:
      first-contentful-paint:
        - error
        - maxNumericValue: 2000
      largest-contentful-paint:
        - error
        - maxNumericValue: 3000
      cumulative-layout-shift:
        - error
        - maxNumericValue: 0.1
      speed-index:
        - error
        - maxNumericValue: 3500
      interactive:
        - error
        - maxNumericValue: 4000
  upload:
    target: temporary-public-storage
```

**CI/CD Integration:**

```yaml
# .github/workflows/lighthouse.yml
- name: Run Lighthouse CI
  run: |
    npm install -g @lhci/cli@0.12.x
    lhci autorun
```

**Aufwand:** 2 Stunden
**Impact:**

- Performance-Guarantees
- Lighthouse-Score >90

---

## üì± TEIL 5: UX-OPTIMIERUNGEN

### üü° WICHTIG (Sprint 50-51)

#### 5.1 Skeleton-Loading (Perceived Performance)

**Problem:** Wei√üe Seite w√§hrend Laden
**Impact:** App wirkt langsam

**L√∂sung:**

```typescript
// Skeleton-Components f√ºr alle Tabellen
function BookingsTableSkeleton() {
  return (
    <div className="space-y-2">
      {Array.from({ length: 10 }).map((_, i) => (
        <div key={i} className="flex gap-4 p-4 border rounded animate-pulse">
          <Skeleton className="h-12 w-12 rounded-full" />
          <div className="flex-1 space-y-2">
            <Skeleton className="h-4 w-[250px]" />
            <Skeleton className="h-4 w-[200px]" />
          </div>
          <Skeleton className="h-8 w-[100px]" />
        </div>
      ))}
    </div>
  );
}

// Usage
{isLoading ? <BookingsTableSkeleton /> : <BookingsTable data={data} />}
```

**Aufwand:** 4 Stunden (alle Seiten)
**Impact:**

- Perceived Performance +50%
- Bessere UX

---

#### 5.2 Keyboard-Shortcuts (Accessibility)

**Problem:** Maus-lastige Navigation
**Impact:** Power-User unzufrieden

**L√∂sung:**

```typescript
// Global Keyboard-Shortcuts
import { useHotkeys } from 'react-hotkeys-hook';

function GlobalShortcuts() {
  useHotkeys('ctrl+k', () => openGlobalSearch());
  useHotkeys('ctrl+n', () => navigate('/auftraege/neu'));
  useHotkeys('ctrl+d', () => navigate('/dashboard'));
  useHotkeys('ctrl+b', () => navigate('/auftraege'));
  useHotkeys('ctrl+,', () => navigate('/einstellungen'));
  useHotkeys('?', () => openShortcutsDialog());

  return null;
}

// Shortcuts-Dialog (?)
<Dialog open={showShortcuts}>
  <DialogContent>
    <DialogTitle>Tastenkombinationen</DialogTitle>
    <div className="grid grid-cols-2 gap-4">
      <ShortcutRow keys={['Ctrl', 'K']} action="Globale Suche" />
      <ShortcutRow keys={['Ctrl', 'N']} action="Neuer Auftrag" />
      <ShortcutRow keys={['Ctrl', 'D']} action="Dashboard" />
      <ShortcutRow keys={['?']} action="Hilfe anzeigen" />
    </div>
  </DialogContent>
</Dialog>
```

**Aufwand:** 3 Stunden
**Impact:**

- Power-User-Zufriedenheit +80%
- Accessibility verbessert

---

#### 5.3 Drag & Drop (Dokumente-Upload)

**Problem:** Umst√§ndlicher Upload-Flow
**Impact:** Schlechte UX

**L√∂sung:**

```typescript
// react-dropzone
import { useDropzone } from 'react-dropzone';

function DocumentUpload() {
  const { getRootProps, getInputProps, isDragActive } = useDropzone({
    accept: {
      'application/pdf': ['.pdf'],
      'image/*': ['.jpg', '.jpeg', '.png'],
    },
    maxFiles: 5,
    maxSize: 5 * 1024 * 1024, // 5MB
    onDrop: async (files) => {
      for (const file of files) {
        await uploadDocument(file);
      }
    },
  });

  return (
    <div
      {...getRootProps()}
      className={cn(
        'border-2 border-dashed rounded-lg p-8 text-center cursor-pointer',
        isDragActive && 'border-primary bg-primary/10'
      )}
    >
      <input {...getInputProps()} />
      <Upload className="h-12 w-12 mx-auto mb-4 text-muted-foreground" />
      {isDragActive ? (
        <p>Dateien hier ablegen...</p>
      ) : (
        <p>Dateien hier ablegen oder klicken zum Ausw√§hlen</p>
      )}
    </div>
  );
}
```

**Aufwand:** 2 Stunden
**Impact:**

- Upload-Convenience +100%
- Bulk-Upload m√∂glich

---

## üéØ TEIL 6: PRIORISIERUNGS-MATRIX

### Nach Business-Impact (ROI)

| Optimierung                   | Aufwand (h) | Impact            | ROI-Score | Priorit√§t |
| ----------------------------- | ----------- | ----------------- | --------- | --------- |
| **Materialized View Refresh** | 1           | Rechtssicherheit  | 10/10     | üî¥ P0     |
| **Input-Validation Backend**  | 4           | Security          | 9/10      | üî¥ P0     |
| **Rate Limiting**             | 2           | Kosten-Schutz     | 9/10      | üî¥ P0     |
| **Database Indexes**          | 2           | Performance       | 8/10      | üî¥ P0     |
| **Optimistic Updates**        | 6           | UX                | 8/10      | üü° P1     |
| **Skeleton-Loading**          | 4           | UX                | 7/10      | üü° P1     |
| **Virtual Scrolling**         | 4           | Performance       | 7/10      | üü° P1     |
| **Code-Splitting**            | 2           | Performance       | 7/10      | üü° P1     |
| **Database Partitioning**     | 4           | Scalability       | 6/10      | üü° P1     |
| **Full-Text-Search**          | 3           | UX                | 6/10      | üü° P1     |
| **Monitoring (Sentry)**       | 4           | Stability         | 6/10      | üü° P1     |
| **Connection Pooling**        | 1           | Stability         | 6/10      | üü° P1     |
| **Service Worker (PWA)**      | 8           | Offline-UX        | 5/10      | üü¢ P2     |
| **Keyboard-Shortcuts**        | 3           | Power-User        | 5/10      | üü¢ P2     |
| **Drag & Drop**               | 2           | UX                | 5/10      | üü¢ P2     |
| **E2E-Tests**                 | 20          | Quality           | 5/10      | üü¢ P2     |
| **Web Workers**               | 4           | Performance       | 4/10      | üü¢ P2     |
| **Read Replicas**             | 2           | Performance       | 4/10      | üü¢ P2     |
| **CSRF-Protection**           | 3           | Security          | 4/10      | üü¢ P2     |
| **Prefetching**               | 3           | UX                | 4/10      | üü¢ P2     |
| **Database Backup**           | 4           | Disaster-Recovery | 3/10      | üü¢ P2     |
| **Lighthouse CI**             | 2           | Quality           | 3/10      | üü¢ P2     |

**Legende:**

- üî¥ P0 (KRITISCH): Sprint 49-50
- üü° P1 (WICHTIG): Sprint 51-52
- üü¢ P2 (ENHANCEMENT): Sprint 53+

### Nach Aufwand (Quick Wins)

**< 2 Stunden:**

1. Materialized View Refresh (1h) - üî¥ P0
2. Connection Pooling (1h) - üü° P1
3. Database Indexes (2h) - üî¥ P0
4. Rate Limiting (2h) - üî¥ P0
5. Code-Splitting (2h) - üü° P1
6. Drag & Drop (2h) - üü¢ P2
7. Lighthouse CI (2h) - üü¢ P2
8. SQL-Injection-Review (2h) - üî¥ P0

**2-5 Stunden:** 9. Full-Text-Search (3h) - üü° P1 10. Prefetching (3h) - üü¢ P2 11. Keyboard-Shortcuts (3h) - üü¢ P2 12. CSRF-Protection (3h) - üü¢ P2 13. Input-Validation (4h) - üî¥ P0 14. Database Partitioning (4h) - üü° P1 15. Virtual Scrolling (4h) - üü° P1 16. Skeleton-Loading (4h) - üü° P1 17. Database Backup (4h) - üü¢ P2 18. Web Workers (4h) - üü¢ P2 19. Monitoring (4h) - üü° P1

---

## üìà ERWARTETE GESAMT-VERBESSERUNG

**Nach Implementierung ALLER P0+P1-Optimierungen:**

| Metrik                  | Vorher | Nachher | Verbesserung |
| ----------------------- | ------ | ------- | ------------ |
| **Initial Load Time**   | 3.2s   | 1.5s    | -53%         |
| **Time-to-Interactive** | 4.8s   | 2.1s    | -56%         |
| **Query-Performance**   | 850ms  | 210ms   | -75%         |
| **Bundle-Size**         | 2.1MB  | 420KB   | -80%         |
| **Lighthouse-Score**    | 78     | 94      | +16          |
| **MTTR (Errors)**       | 4h     | 1h      | -75%         |
| **Perceived Speed**     | 6/10   | 9/10    | +50%         |

**Kosten-Impact:**

- Server-Kosten: -40% (Rate-Limiting, Caching)
- Development-Zeit: -30% (weniger Bugs)
- Support-Anfragen: -50% (bessere UX)

---

## üöÄ ROADMAP-√úBERSICHT

```
Sprint 49-50 (P0 - KRITISCH):
‚úÖ Materialized View Refresh
‚úÖ Database Indexes
‚úÖ Rate Limiting
‚úÖ Input-Validation Backend
‚úÖ SQL-Injection-Review
Gesch√§tzter Aufwand: 15 Stunden

Sprint 51-52 (P1 - WICHTIG):
‚úÖ Optimistic Updates
‚úÖ Virtual Scrolling
‚úÖ Code-Splitting
‚úÖ Database Partitioning
‚úÖ Full-Text-Search
‚úÖ Connection Pooling
‚úÖ Monitoring (Sentry)
‚úÖ Skeleton-Loading
Gesch√§tzter Aufwand: 32 Stunden

Sprint 53+ (P2 - ENHANCEMENT):
‚úÖ Service Worker (PWA)
‚úÖ Keyboard-Shortcuts
‚úÖ Drag & Drop
‚úÖ E2E-Tests
‚úÖ Web Workers
‚úÖ CSRF-Protection
‚úÖ Prefetching
‚úÖ Database Backup
‚úÖ Lighthouse CI
Gesch√§tzter Aufwand: 50 Stunden
```

**Gesamt-Aufwand:** ~97 Stunden (12 Entwicklertage)

---

_Version: V18.3_
_Datum: 18.01.2025_
_Status: üü° PLANUNG - Bereit zur Umsetzung_
